project: frontier-model-framework
artefacts_dir: artefacts

auth:
  provider: env

connectors:
  - name: local_docs
    type: local
    root: ./data
    include: ["**/*.md", "**/*.txt", "**/*.{png,jpg,jpeg}"]

processing:
  text:
    normalize_whitespace: true
    preserve_markdown: true
    chunking: { strategy: recursive, max_tokens: 800, overlap: 150, splitter: by_sentence }
  tables:
    to_markdown: true
  images:
    ocr: { enabled: false }

rag:
  pipelines:
    - name: local_docs_rag
      connector: local_docs
      select: ["**/*.md", "**/*.txt"]
      modalities: ["text"]
      max_text_items: 5
    - name: sample_images
      connector: local_docs
      select: ["**/*.{png,jpg,jpeg}"]
      modalities: ["image"]
      max_image_items: 10
      build_concurrency: 4

inference:
  provider: azure_openai
  azure_openai:
    endpoint: https://<your-resource>.openai.azure.com/
    api_version: 2024-02-15-preview
    deployment: gpt-4o-mini
    temperature: 0.2
    max_tokens: 256

export:
  sinks:
    - name: s3_results
      type: s3
      bucket: my-bucket
      prefix: fmf/outputs/${run_id}/
      format: jsonl
      compression: gzip

prompt_registry:
  backend: local_yaml
  path: ./examples
  index_file: prompts/index.yaml

run:
  chain_config: ./examples/chains/sample.yaml
  inputs: { connector: local_docs, select: ["**/*.md"] }
